{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731e9fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from scipy import fftpack\n",
    "import glob\n",
    "import shutil\n",
    "import pydicom  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77dd9804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new dataset saved under seperated_data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "def organize_and_clean_files(base_path, target_path):\n",
    "    \n",
    "    sub_folders = [\"PREOP UZ\", \"PREOP AP\", \"POSTOP UZ\", \"POSTOP AP\"]\n",
    "    \n",
    "    if not os.path.exists(target_path):\n",
    "        os.makedirs(target_path)\n",
    "\n",
    "    for folder in sub_folders:\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            print(f\"Klasör bulunamadı: {folder_path}\")\n",
    "            continue\n",
    "\n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if not file_name.endswith(\".dcm\"):\n",
    "                continue\n",
    "            match = re.search(r\"^(.*?)\\s*(POSTOP|PREOP)\", file_name)\n",
    "            \n",
    "            if match:\n",
    "                patient_name_raw = match.group(1).strip()\n",
    "                patient_folder_name = patient_name_raw.replace(\" \", \"_\").lower()\n",
    "                \n",
    "                suffix = folder.replace(\" \", \"_\").lower()\n",
    "                \n",
    "                patient_dir = os.path.join(target_path, patient_folder_name)\n",
    "                os.makedirs(patient_dir, exist_ok=True)\n",
    "                \n",
    "                new_file_name = f\"{patient_folder_name}_{suffix}.dcm\"\n",
    "                \n",
    "                source_full_path = os.path.join(folder_path, file_name)\n",
    "                target_full_path = os.path.join(patient_dir, new_file_name)\n",
    "                \n",
    "                shutil.copy2(source_full_path, target_full_path)\n",
    "            else:\n",
    "                print(f\"Format eşleşmedi, atlanıyor: {file_name}\")\n",
    "\n",
    "    print(f\"new dataset saved under {target_path}\")\n",
    "\n",
    "organize_and_clean_files(\"raw_data\", \"seperated_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5bbecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def create_patient_dict_with_missing(base_path):\n",
    "    \"\"\"\n",
    "    { 'name_surname': ['path/to/preop_uz', '', 'path/to/postop_uz', ''] }\n",
    "    \"\"\"\n",
    "    sub_folders = [\"PREOP UZ\", \"PREOP AP\", \"POSTOP UZ\", \"POSTOP AP\"]\n",
    "    patient_dict = {}\n",
    "    \n",
    "    all_patients = set()\n",
    "    \n",
    "    for folder in sub_folders:\n",
    "        folder_path = os.path.join(base_path, folder)\n",
    "        if not os.path.exists(folder_path):\n",
    "            continue\n",
    "            \n",
    "        for file_name in os.listdir(folder_path):\n",
    "            if file_name.endswith(\".dcm\"):\n",
    "                match = re.search(r\"^(.*?)\\s*(POSTOP|PREOP)\", file_name)\n",
    "                if match:\n",
    "                    patient_name = match.group(1).strip()\n",
    "                    all_patients.add(patient_name)\n",
    "\n",
    "    for patient in all_patients:\n",
    "        patient_paths = []\n",
    "        \n",
    "        for folder in sub_folders:\n",
    "            folder_path = os.path.join(base_path, folder)\n",
    "            found = False\n",
    "            \n",
    "            if os.path.exists(folder_path):\n",
    "                for file_name in os.listdir(folder_path):\n",
    "                    if file_name.startswith(patient) and file_name.endswith(\".dcm\"):\n",
    "                        full_path = os.path.join(folder_path, file_name)\n",
    "                        patient_paths.append(full_path)\n",
    "                        found = True\n",
    "                        break\n",
    "            \n",
    "            if not found:\n",
    "                patient_paths.append(\"\") \n",
    "        \n",
    "        patient_dict[patient] = patient_paths\n",
    "        \n",
    "    return patient_dict\n",
    "\n",
    "base_path = \"./raw_data\"\n",
    "patients = create_patient_dict_with_missing(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3a946a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52fd2582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kategorik medyan boyutlar hesaplanıyor...\n",
      "-> PREOP_UZ Medyan Boyut: 1760x2140\n",
      "-> PREOP_AP Medyan Boyut: 1760x2140\n",
      "-> POSTOP_UZ Medyan Boyut: 1760x2140\n",
      "-> POSTOP_AP Medyan Boyut: 1760x2140\n"
     ]
    }
   ],
   "source": [
    "def calculate_category_medians(patient_dict):\n",
    "    \"\"\"\n",
    "    Kategorilere göre (0: PREOP UZ, 1: PREOP AP, 2: POSTOP UZ, 3: POSTOP AP)\n",
    "    ayrı ayrı medyan boyutları hesaplar.\n",
    "    \"\"\"\n",
    "    # 4 kategori için ayrı listeler tutalım\n",
    "    categories_dims = {\n",
    "        0: {\"widths\": [], \"heights\": []}, # PREOP UZ\n",
    "        1: {\"widths\": [], \"heights\": []}, # PREOP AP\n",
    "        2: {\"widths\": [], \"heights\": []}, # POSTOP UZ\n",
    "        3: {\"widths\": [], \"heights\": []}  # POSTOP AP\n",
    "    }\n",
    "    \n",
    "    print(\"Kategorik medyan boyutlar hesaplanıyor...\")\n",
    "\n",
    "    for patient, paths in patient_dict.items():\n",
    "        for i in range(4):\n",
    "            file_path = paths[i]\n",
    "            \n",
    "            # Eğer dosya yolu boş değilse ve dosya mevcutsa boyutunu oku\n",
    "            if file_path != \"\" and os.path.exists(file_path):\n",
    "                try:\n",
    "                    # Görüntü verisini yüklemeden sadece metadata'dan boyut okumak daha hızlıdır\n",
    "                    ds = pydicom.dcmread(file_path, stop_before_pixels=True)\n",
    "                    h, w = ds.Rows, ds.Columns\n",
    "                    \n",
    "                    categories_dims[i][\"widths\"].append(w)\n",
    "                    categories_dims[i][\"heights\"].append(h)\n",
    "                except Exception as e:\n",
    "                    print(f\"Hata: {file_path} okunamadı. {e}\")\n",
    "\n",
    "    # Her kategori için medyanları hesapla\n",
    "    final_medians = {}\n",
    "    category_names = [\"PREOP_UZ\", \"PREOP_AP\", \"POSTOP_UZ\", \"POSTOP_AP\"]\n",
    "    \n",
    "    for i in range(4):\n",
    "        if categories_dims[i][\"widths\"]: # Liste boş değilse\n",
    "            m_w = int(np.median(categories_dims[i][\"widths\"]))\n",
    "            m_h = int(np.median(categories_dims[i][\"heights\"]))\n",
    "            final_medians[i] = (m_w, m_h)\n",
    "            print(f\"-> {category_names[i]} Medyan Boyut: {m_w}x{m_h}\")\n",
    "        else:\n",
    "            final_medians[i] = (256, 256) # Fallback: Veri yoksa standart boyut\n",
    "            print(f\"-> {category_names[i]} için veri bulunamadı, varsayılan (256, 256) atandı.\")\n",
    "\n",
    "    return final_medians\n",
    "\n",
    "medians = calculate_category_medians(patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "454c3da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: (1760, 2140), 1: (1760, 2140), 2: (1760, 2140), 3: (1760, 2140)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51b29b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_butterworth_filter(img, order=4, cutoff_factor=0.5):\n",
    "    rows, cols = img.shape\n",
    "    f_transform = np.fft.fft2(img)\n",
    "    f_shift = np.fft.fftshift(f_transform)\n",
    "\n",
    "    crow, ccol = rows // 2, cols // 2\n",
    "    y, x = np.ogrid[-crow:rows-crow, -ccol:cols-ccol]\n",
    "\n",
    "    d0 = (min(rows, cols) / 2) * cutoff_factor\n",
    "    dist = np.sqrt(x**2 + y**2)\n",
    "\n",
    "    mask = 1 / (1 + (dist / d0)**(2 * order))\n",
    "\n",
    "    f_shift_filtered = f_shift * mask\n",
    "    f_ishift = np.fft.ifftshift(f_shift_filtered)\n",
    "    img_back = np.fft.ifft2(f_ishift)\n",
    "\n",
    "    return np.abs(img_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68a106ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img, target_size):\n",
    "    return cv2.resize(img, target_size, interpolation=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df423bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_as_npy(data, filename):\n",
    "    np.save(filename, data)\n",
    "    print(f\"file saved: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e72b858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./raw_data/PREOP UZ/FATMA TURGUT PREOP UZ.Seq1.Ser1009.Img1.dcm',\n",
       " './raw_data/PREOP AP/FATMA TURGUT PREOP AP.Seq1.Ser1.Img1.dcm',\n",
       " '',\n",
       " './raw_data/POSTOP AP/FATMA TURGUT POSTOP AP.Seq2.Ser1002.Img1.dcm']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patients[\"FATMA TURGUT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3a171616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting: PREOP AP | Total: 205\n",
      "Progress: 0/205\n",
      "Progress: 10/205\n",
      "Progress: 20/205\n",
      "Progress: 30/205\n",
      "Progress: 40/205\n",
      "Progress: 50/205\n",
      "Progress: 60/205\n",
      "Progress: 70/205\n",
      "Progress: 80/205\n",
      "Progress: 90/205\n",
      "Progress: 100/205\n",
      "Progress: 110/205\n",
      "Progress: 120/205\n",
      "Progress: 130/205\n",
      "Progress: 140/205\n",
      "Progress: 150/205\n",
      "Progress: 160/205\n",
      "Progress: 170/205\n",
      "Progress: 180/205\n",
      "Progress: 190/205\n",
      "Progress: 200/205\n",
      "Finished: preop_ap.npy\n"
     ]
    }
   ],
   "source": [
    "selected_category = \"PREOP AP\"\n",
    "category_index = 1 \n",
    "base_path = \"./raw_data\"\n",
    "target_size = medians[category_index] \n",
    "target_h, target_w = target_size[1], target_size[0]\n",
    "\n",
    "category_path = os.path.join(base_path, selected_category)\n",
    "file_list = sorted([f for f in os.listdir(category_path) if f.endswith('.dcm')])\n",
    "num_images = len(file_list)\n",
    "\n",
    "output_filename = f\"{selected_category.replace(' ', '_').lower()}.npy\"\n",
    "\n",
    "data_shape = (num_images, target_h, target_w)\n",
    "fp = np.memmap(output_filename, dtype='float32', mode='w+', shape=data_shape)\n",
    "\n",
    "print(f\"Starting: {selected_category} | Total: {num_images}\")\n",
    "\n",
    "for i, file_name in enumerate(file_list):\n",
    "    try:\n",
    "        file_path = os.path.join(category_path, file_name)\n",
    "        \n",
    "        ds = pydicom.dcmread(file_path)\n",
    "        img = ds.pixel_array.astype(np.float32)\n",
    "        \n",
    "        img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-8)\n",
    "        \n",
    "        filtered = apply_butterworth_filter(img, order=4)\n",
    "        resized = resize_image(filtered, target_size)\n",
    "        \n",
    "        fp[i, :, :] = resized\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            fp.flush()\n",
    "            print(f\"Progress: {i}/{num_images}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error at {file_name}: {e}\")\n",
    "        fp[i, :, :] = np.zeros((target_h, target_w), dtype=np.float32)\n",
    "\n",
    "fp.flush()\n",
    "del fp \n",
    "print(f\"Finished: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "42f463a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find number of images under a category\n",
    "selected_category = \"PREOP UZ\"\n",
    "category_index = 1 \n",
    "base_path = \"./raw_data\"\n",
    "target_size = medians[category_index] \n",
    "target_h, target_w = target_size[1], target_size[0]\n",
    "\n",
    "category_path = os.path.join(base_path, selected_category)\n",
    "file_list = sorted([f for f in os.listdir(category_path) if f.endswith('.dcm')])\n",
    "num_images = len(file_list)\n",
    "num_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "062a3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# memmap to actual .npy\n",
    "import os\n",
    "import numpy as np\n",
    "file_path = \"preop_ap.npy\"\n",
    "target_size = (1760, 2140)\n",
    "bytes_per_pixel = 4\n",
    "\n",
    "total_bytes = os.path.getsize(file_path)\n",
    "\n",
    "frame_bytes = target_size[0] * target_size[1] * bytes_per_pixel\n",
    "\n",
    "num_images = total_bytes // frame_bytes\n",
    "\n",
    "final_shape = (num_images, target_size[1], target_size[0])\n",
    "\n",
    "temp_data = np.memmap(file_path, dtype='float32', mode='r', shape=final_shape)\n",
    "np.save(file_path, temp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef19bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toplam tam verili hasta sayısı: 12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def get_perfect_patient_dict(base_path):\n",
    "    categories = [\"PREOP UZ\", \"PREOP AP\", \"POSTOP UZ\", \"POSTOP AP\"]\n",
    "    potential_names = set()\n",
    "    \n",
    "    for cat in categories:\n",
    "        cat_path = os.path.join(base_path, cat)\n",
    "        if os.path.exists(cat_path):\n",
    "            for file_name in os.listdir(cat_path):\n",
    "                if file_name.endswith(\".dcm\"):\n",
    "                    match = re.search(r\"^(.*?)\\s*(POSTOP|PREOP)\", file_name)\n",
    "                    if match:\n",
    "                        potential_names.add(match.group(1).strip())\n",
    "\n",
    "    perfect_dict = {}\n",
    "\n",
    "    for name in sorted(potential_names):\n",
    "        temp_paths = []\n",
    "        is_complete = True\n",
    "        \n",
    "        for cat in categories:\n",
    "            cat_path = os.path.join(base_path, cat)\n",
    "            found_path = \"\"\n",
    "            \n",
    "            if os.path.exists(cat_path):\n",
    "                for file_name in os.listdir(cat_path):\n",
    "                    if file_name.startswith(name) and file_name.endswith(\".dcm\"):\n",
    "                        found_path = os.path.join(cat_path, file_name)\n",
    "                        break\n",
    "            \n",
    "            # Eğer bir kategoride bile resim bulunamazsa is_complete False olur\n",
    "            if found_path == \"\":\n",
    "                is_complete = False\n",
    "                break\n",
    "            else:\n",
    "                temp_paths.append(found_path)\n",
    "        \n",
    "        # Sadece 4 resmi de bulunan hastaları sözlüğe ekle\n",
    "        if is_complete:\n",
    "            perfect_dict[name] = temp_paths\n",
    "            \n",
    "    return perfect_dict\n",
    "\n",
    "# --- Kullanım ---\n",
    "base_path = \"./raw_data\"\n",
    "final_perfect_dict = get_perfect_patient_dict(base_path)\n",
    "\n",
    "print(f\"Toplam tam verili hasta sayısı: {len(final_perfect_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21f525db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset oluşturuluyor. Toplam Hasta: 12 | Hedef Boyut: (12, 4, 2140, 1760)\n",
      "İşleniyor (1/12): EMİNE EREN\n",
      "İşleniyor (2/12): EVA LUGOVAIA\n",
      "İşleniyor (3/12): FATMA EMEL YAŞA\n",
      "İşleniyor (4/12): HATİCE SEZER\n",
      "İşleniyor (5/12): HATİCE ÇALIŞKAN\n",
      "İşleniyor (6/12): KAFİYE ÇAKMAK\n",
      "İşleniyor (7/12): MİNE ERDEN\n",
      "İşleniyor (8/12): NEBAHAT ZAZAOĞLU\n",
      "İşleniyor (9/12): NURHAN IŞIK\n",
      "İşleniyor (10/12): SOLMAZ ÜLKER\n",
      "İşleniyor (11/12): SUZAN BOZKAYA\n",
      "İşleniyor (12/12): TİMUR ÇAKMAK\n",
      "\n",
      "İşlem tamamlandı: final_dataset_4d.npy hazır.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pydicom\n",
    "\n",
    "# Ayarlar\n",
    "target_size = (1760, 2140) # (Genişlik, Yükseklik)\n",
    "target_w, target_h = target_size\n",
    "num_patients = len(final_perfect_dict)\n",
    "output_filename = \"final_dataset_4d.npy\"\n",
    "\n",
    "# 4D Shape: (Hasta Sayısı, 4 Çekim, Yükseklik, Genişlik)\n",
    "data_shape = (num_patients, 4, target_h, target_w)\n",
    "\n",
    "# Diskte yer ayır (RAM harcamaz)\n",
    "fp = np.memmap(output_filename, dtype='float32', mode='w+', shape=data_shape)\n",
    "\n",
    "print(f\"Dataset oluşturuluyor. Toplam Hasta: {num_patients} | Hedef Boyut: {data_shape}\")\n",
    "\n",
    "for i, (name, paths) in enumerate(final_perfect_dict.items()):\n",
    "    print(f\"İşleniyor ({i+1}/{num_patients}): {name}\")\n",
    "    \n",
    "    for j, file_path in enumerate(paths):\n",
    "        try:\n",
    "            # 1. Import\n",
    "            ds = pydicom.dcmread(file_path)\n",
    "            img = ds.pixel_array.astype(np.float32)\n",
    "            \n",
    "            # Normalizasyon\n",
    "            img = (img - np.min(img)) / (np.max(img) - np.min(img) + 1e-8)\n",
    "            \n",
    "            # 2. Butterworth 4. Derece Filtre\n",
    "            filtered = apply_butterworth_filter(img, order=4)\n",
    "            \n",
    "            # 3. Resize\n",
    "            resized = resize_image(filtered, target_size)\n",
    "            \n",
    "            # 4. 4D matrisin ilgili hücresine yaz (Hasta i, Çekim j)\n",
    "            fp[i, j, :, :] = resized\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Hata: {name}, Çekim {j} -> {e}\")\n",
    "            fp[i, j, :, :] = np.zeros((target_h, target_w), dtype=np.float32)\n",
    "            \n",
    "    # Her hasta bittiğinde diske yazmayı onayla\n",
    "    fp.flush()\n",
    "\n",
    "# Bağlantıları temizle\n",
    "del fp\n",
    "print(f\"\\nİşlem tamamlandı: {output_filename} hazır.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d04ec4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected: 3088448000 bytes\n",
      "Actual:   3088448128 bytes\n",
      "Match: NO (Diff: 128)\n"
     ]
    }
   ],
   "source": [
    "# validity check\n",
    "def validate_dataset(file_path, n_patients, size):\n",
    "    if not os.path.exists(file_path):\n",
    "        return\n",
    "    \n",
    "    expected = n_patients * size[1] * size[0] * 4\n",
    "    actual = os.path.getsize(file_path)\n",
    "    \n",
    "    print(f\"Expected: {expected} bytes\")\n",
    "    print(f\"Actual:   {actual} bytes\")\n",
    "    print(\"Match: \" + (\"YES\" if expected == actual else f\"NO (Diff: {actual - expected})\"))\n",
    "\n",
    "validate_dataset(\"preop_ap.npy\", 205, (1760, 2140))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
