{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b818bbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0de6e527",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '../all-preop-LLRs/'\n",
    "images = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith(('.jpg', '.png'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ecca6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project \"/home/furkan/projects/cpak/deeplabcut/cpak-furkan-2026-02-18\" already exists!\n"
     ]
    }
   ],
   "source": [
    "# create project\n",
    "# project_name=\"cpak\"\n",
    "# name=\"furkan\"\n",
    "# config_path = deeplabcut.create_new_project(project_name, name, images, copy_videos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5061002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default augmenter albumentations not available for engine Engine.PYTORCH: using albumentations instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.95,\n",
       "  1,\n",
       "  (array([19, 16, 15, 26,  4, 12, 37, 27, 39,  6, 25,  9, 13, 31, 34,  8, 17,\n",
       "          24,  0, 33,  5, 11,  1, 29, 21,  2, 30, 36,  3, 35, 23, 32, 10, 22,\n",
       "          18, 20,  7, 14]),\n",
       "   array([28, 38]))),\n",
       " (0.95,\n",
       "  2,\n",
       "  (array([22,  0, 26,  4, 32, 18, 10, 33, 15, 12, 31,  9, 23,  5, 21, 30, 29,\n",
       "          35, 37, 36, 16, 34,  2, 28,  7, 11,  6, 14, 27, 19,  1, 20, 25, 39,\n",
       "          13, 24,  3, 17]),\n",
       "   array([38,  8])))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path = \"/home/furkan/projects/cpak/deeplabcut/cpak-furkan-2026-02-17/config.yaml\"\n",
    "# deeplabcut.convertcsv2h5(config_path, scorer=\"murkanthedestroyer\", userfeedback=False)\n",
    "deeplabcut.create_training_dataset(config_path, num_shuffles=2, net_type='resnet_50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce9e72b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training with configuration:\n",
      "data:\n",
      "  bbox_margin: 20\n",
      "  colormode: RGB\n",
      "  inference:\n",
      "    normalize_images: True\n",
      "  train:\n",
      "    affine:\n",
      "      p: 0.5\n",
      "      rotation: 30\n",
      "      scaling: [0.5, 1.25]\n",
      "      translation: 0\n",
      "    crop_sampling:\n",
      "      width: 448\n",
      "      height: 448\n",
      "      max_shift: 0.1\n",
      "      method: hybrid\n",
      "    gaussian_noise: 12.75\n",
      "    motion_blur: True\n",
      "    normalize_images: True\n",
      "device: auto\n",
      "inference:\n",
      "  multithreading:\n",
      "    enabled: True\n",
      "    queue_length: 4\n",
      "    timeout: 30.0\n",
      "  compile:\n",
      "    enabled: False\n",
      "    backend: inductor\n",
      "  autocast:\n",
      "    enabled: False\n",
      "metadata:\n",
      "  project_path: /home/furkan/projects/cpak/deeplabcut/cpak-furkan-2026-02-17\n",
      "  pose_config_path: /home/furkan/projects/cpak/deeplabcut/cpak-furkan-2026-02-17/dlc-models-pytorch/iteration-0/cpakFeb17-trainset95shuffle2/train/pytorch_config.yaml\n",
      "  bodyparts: ['1', '2', '3', '4', '5', '6', '7']\n",
      "  unique_bodyparts: []\n",
      "  individuals: ['animal']\n",
      "  with_identity: None\n",
      "method: bu\n",
      "model:\n",
      "  backbone:\n",
      "    type: ResNet\n",
      "    model_name: resnet50_gn\n",
      "    output_stride: 16\n",
      "    freeze_bn_stats: False\n",
      "    freeze_bn_weights: False\n",
      "  backbone_output_channels: 2048\n",
      "  heads:\n",
      "    bodypart:\n",
      "      type: HeatmapHead\n",
      "      weight_init: normal\n",
      "      predictor:\n",
      "        type: HeatmapPredictor\n",
      "        apply_sigmoid: False\n",
      "        clip_scores: True\n",
      "        location_refinement: True\n",
      "        locref_std: 7.2801\n",
      "      target_generator:\n",
      "        type: HeatmapGaussianGenerator\n",
      "        num_heatmaps: 7\n",
      "        pos_dist_thresh: 17\n",
      "        heatmap_mode: KEYPOINT\n",
      "        gradient_masking: False\n",
      "        generate_locref: True\n",
      "        locref_std: 7.2801\n",
      "      criterion:\n",
      "        heatmap:\n",
      "          type: WeightedMSECriterion\n",
      "          weight: 1.0\n",
      "        locref:\n",
      "          type: WeightedHuberCriterion\n",
      "          weight: 0.05\n",
      "      heatmap_config:\n",
      "        channels: [2048, 7]\n",
      "        kernel_size: [3]\n",
      "        strides: [2]\n",
      "      locref_config:\n",
      "        channels: [2048, 14]\n",
      "        kernel_size: [3]\n",
      "        strides: [2]\n",
      "net_type: resnet_50\n",
      "runner:\n",
      "  type: PoseTrainingRunner\n",
      "  gpus: None\n",
      "  key_metric: test.mAP\n",
      "  key_metric_asc: True\n",
      "  eval_interval: 10\n",
      "  optimizer:\n",
      "    type: AdamW\n",
      "    params:\n",
      "      lr: 0.0005\n",
      "  scheduler:\n",
      "    type: LRListScheduler\n",
      "    params:\n",
      "      lr_list: [[0.0001], [1e-05]]\n",
      "      milestones: [90, 120]\n",
      "  snapshots:\n",
      "    max_snapshots: 5\n",
      "    save_epochs: 25\n",
      "    save_optimizer_state: False\n",
      "train_settings:\n",
      "  batch_size: 8\n",
      "  dataloader_workers: 0\n",
      "  dataloader_pin_memory: False\n",
      "  display_iters: 100\n",
      "  epochs: 200\n",
      "  seed: 42\n",
      "Loading pretrained weights from Hugging Face hub (timm/resnet50_gn.a1h_in1k)\n",
      "HTTP Request: HEAD https://huggingface.co/timm/resnet50_gn.a1h_in1k/resolve/main/model.safetensors \"HTTP/1.1 302 Found\"\n",
      "[timm/resnet50_gn.a1h_in1k] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "Data Transforms:\n",
      "  Training:   Compose([\n",
      "  Affine(always_apply=False, p=0.5, interpolation=1, mask_interpolation=0, cval=0, mode=0, scale={'x': (0.5, 1.25), 'y': (0.5, 1.25)}, translate_percent=None, translate_px={'x': (0, 0), 'y': (0, 0)}, rotate=(-30, 30), fit_output=False, shear={'x': (0.0, 0.0), 'y': (0.0, 0.0)}, cval_mask=0, keep_ratio=True, rotate_method='largest_box'),\n",
      "  PadIfNeeded(always_apply=True, p=1.0, min_height=448, min_width=448, pad_height_divisor=None, pad_width_divisor=None, position=PositionType.CENTER, border_mode=0, value=None, mask_value=None),\n",
      "  KeypointAwareCrop(always_apply=True, p=1.0, width=448, height=448, max_shift=0.1, crop_sampling='hybrid'),\n",
      "  MotionBlur(always_apply=False, p=0.5, blur_limit=(3, 7), allow_shifted=True),\n",
      "  GaussNoise(always_apply=False, p=0.5, var_limit=(0, 162.5625), per_channel=True, mean=0),\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)\n",
      "  Validation: Compose([\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "], p=1.0, bbox_params={'format': 'coco', 'label_fields': ['bbox_labels'], 'min_area': 0.0, 'min_visibility': 0.0, 'min_width': 0.0, 'min_height': 0.0, 'check_each_transform': True}, keypoint_params={'format': 'xy', 'label_fields': ['class_labels'], 'remove_invisible': False, 'angle_in_degrees': True, 'check_each_transform': True}, additional_targets={}, is_check_shapes=True)\n",
      "Using 38 images and 2 for testing\n",
      "\n",
      "Starting pose model training...\n",
      "--------------------------------------------------\n",
      "Epoch 1/200 (lr=0.0005), train loss 0.01564, GPU: 3840.0/5804.3 MiB\n",
      "Epoch 2/200 (lr=0.0005), train loss 0.01456, GPU: 3840.0/5804.3 MiB\n",
      "Epoch 3/200 (lr=0.0005), train loss 0.01458, GPU: 3840.0/5804.3 MiB\n",
      "Epoch 4/200 (lr=0.0005), train loss 0.01451, GPU: 3840.0/5804.3 MiB\n",
      "Epoch 5/200 (lr=0.0005), train loss 0.01422, GPU: 3840.0/5804.3 MiB\n",
      "Epoch 6/200 (lr=0.0005), train loss 0.01393, GPU: 3840.0/5804.3 MiB\n",
      "Epoch 7/200 (lr=0.0005), train loss 0.01298, GPU: 3840.0/5804.3 MiB\n",
      "Epoch 8/200 (lr=0.0005), train loss 0.00968, GPU: 3840.0/5804.3 MiB\n",
      "Epoch 9/200 (lr=0.0005), train loss 0.01204, GPU: 3840.0/5804.3 MiB\n",
      "Training for epoch 10 done, starting evaluation\n",
      "Epoch 10/200 (lr=0.0005), train loss 0.01203, valid loss 0.01218, GPU: 3006.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         1129.97\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:            0.00\n",
      "  metrics/test.mAR:            0.00\n",
      "Epoch 11/200 (lr=0.0005), train loss 0.01319, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 12/200 (lr=0.0005), train loss 0.01117, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 13/200 (lr=0.0005), train loss 0.01092, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 14/200 (lr=0.0005), train loss 0.01166, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 15/200 (lr=0.0005), train loss 0.01157, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 16/200 (lr=0.0005), train loss 0.01066, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 17/200 (lr=0.0005), train loss 0.00999, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 18/200 (lr=0.0005), train loss 0.00927, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 19/200 (lr=0.0005), train loss 0.00952, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 20 done, starting evaluation\n",
      "Epoch 20/200 (lr=0.0005), train loss 0.00822, valid loss 0.01042, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         930.56\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:            0.00\n",
      "  metrics/test.mAR:            0.00\n",
      "Epoch 21/200 (lr=0.0005), train loss 0.00878, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 22/200 (lr=0.0005), train loss 0.00868, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 23/200 (lr=0.0005), train loss 0.01040, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 24/200 (lr=0.0005), train loss 0.00792, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 25/200 (lr=0.0005), train loss 0.00992, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 26/200 (lr=0.0005), train loss 0.00857, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 27/200 (lr=0.0005), train loss 0.00954, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 28/200 (lr=0.0005), train loss 0.00958, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 29/200 (lr=0.0005), train loss 0.00753, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 30 done, starting evaluation\n",
      "Epoch 30/200 (lr=0.0005), train loss 0.00860, valid loss 0.00838, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         1077.36\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           15.15\n",
      "  metrics/test.mAR:           15.00\n",
      "Epoch 31/200 (lr=0.0005), train loss 0.00916, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 32/200 (lr=0.0005), train loss 0.00826, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 33/200 (lr=0.0005), train loss 0.00730, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 34/200 (lr=0.0005), train loss 0.00782, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 35/200 (lr=0.0005), train loss 0.00609, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 36/200 (lr=0.0005), train loss 0.00712, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 37/200 (lr=0.0005), train loss 0.00863, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 38/200 (lr=0.0005), train loss 0.00785, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 39/200 (lr=0.0005), train loss 0.00781, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 40 done, starting evaluation\n",
      "Epoch 40/200 (lr=0.0005), train loss 0.00766, valid loss 0.00964, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         973.11\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           10.00\n",
      "  metrics/test.mAR:           10.00\n",
      "Epoch 41/200 (lr=0.0005), train loss 0.00753, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 42/200 (lr=0.0005), train loss 0.00648, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 43/200 (lr=0.0005), train loss 0.00738, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 44/200 (lr=0.0005), train loss 0.00699, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 45/200 (lr=0.0005), train loss 0.00760, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 46/200 (lr=0.0005), train loss 0.00691, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 47/200 (lr=0.0005), train loss 0.00661, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 48/200 (lr=0.0005), train loss 0.00735, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 49/200 (lr=0.0005), train loss 0.00488, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 50 done, starting evaluation\n",
      "Epoch 50/200 (lr=0.0005), train loss 0.00722, valid loss 0.00844, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         784.30\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           15.15\n",
      "  metrics/test.mAR:           15.00\n",
      "Epoch 51/200 (lr=0.0005), train loss 0.00881, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 52/200 (lr=0.0005), train loss 0.00706, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 53/200 (lr=0.0005), train loss 0.00708, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 54/200 (lr=0.0005), train loss 0.00790, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 55/200 (lr=0.0005), train loss 0.00731, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 56/200 (lr=0.0005), train loss 0.00695, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 57/200 (lr=0.0005), train loss 0.00709, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 58/200 (lr=0.0005), train loss 0.00662, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 59/200 (lr=0.0005), train loss 0.00700, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 60 done, starting evaluation\n",
      "Epoch 60/200 (lr=0.0005), train loss 0.00674, valid loss 0.00702, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         1388.89\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:            0.00\n",
      "  metrics/test.mAR:            0.00\n",
      "Epoch 61/200 (lr=0.0005), train loss 0.00726, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 62/200 (lr=0.0005), train loss 0.00729, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 63/200 (lr=0.0005), train loss 0.00675, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 64/200 (lr=0.0005), train loss 0.00748, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 65/200 (lr=0.0005), train loss 0.00670, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 66/200 (lr=0.0005), train loss 0.00710, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 67/200 (lr=0.0005), train loss 0.00648, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 68/200 (lr=0.0005), train loss 0.00720, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 69/200 (lr=0.0005), train loss 0.00518, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 70 done, starting evaluation\n",
      "Epoch 70/200 (lr=0.0005), train loss 0.00622, valid loss 0.00824, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         1165.55\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           10.10\n",
      "  metrics/test.mAR:           20.00\n",
      "Epoch 71/200 (lr=0.0005), train loss 0.00677, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 72/200 (lr=0.0005), train loss 0.00568, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 73/200 (lr=0.0005), train loss 0.00674, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 74/200 (lr=0.0005), train loss 0.00598, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 75/200 (lr=0.0005), train loss 0.00594, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 76/200 (lr=0.0005), train loss 0.00634, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 77/200 (lr=0.0005), train loss 0.00489, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 78/200 (lr=0.0005), train loss 0.00684, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 79/200 (lr=0.0005), train loss 0.00589, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 80 done, starting evaluation\n",
      "Epoch 80/200 (lr=0.0005), train loss 0.00652, valid loss 0.00690, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         1920.92\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:            5.05\n",
      "  metrics/test.mAR:            5.00\n",
      "Epoch 81/200 (lr=0.0005), train loss 0.00497, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 82/200 (lr=0.0005), train loss 0.00563, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 83/200 (lr=0.0005), train loss 0.00570, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 84/200 (lr=0.0005), train loss 0.00633, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 85/200 (lr=0.0005), train loss 0.00608, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 86/200 (lr=0.0005), train loss 0.00628, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 87/200 (lr=0.0005), train loss 0.00570, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 88/200 (lr=0.0005), train loss 0.00586, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 89/200 (lr=0.0005), train loss 0.00701, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 90 done, starting evaluation\n",
      "Epoch 90/200 (lr=0.0001), train loss 0.00904, valid loss 0.00776, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         1291.54\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           30.30\n",
      "  metrics/test.mAR:           30.00\n",
      "Epoch 91/200 (lr=0.0001), train loss 0.00511, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 92/200 (lr=0.0001), train loss 0.00655, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 93/200 (lr=0.0001), train loss 0.00688, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 94/200 (lr=0.0001), train loss 0.00586, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 95/200 (lr=0.0001), train loss 0.00481, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 96/200 (lr=0.0001), train loss 0.00541, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 97/200 (lr=0.0001), train loss 0.00610, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 98/200 (lr=0.0001), train loss 0.00607, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 99/200 (lr=0.0001), train loss 0.00497, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 100 done, starting evaluation\n",
      "Epoch 100/200 (lr=0.0001), train loss 0.00596, valid loss 0.00737, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         985.03\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           20.20\n",
      "  metrics/test.mAR:           20.00\n",
      "Epoch 101/200 (lr=0.0001), train loss 0.00545, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 102/200 (lr=0.0001), train loss 0.00625, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 103/200 (lr=0.0001), train loss 0.00475, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 104/200 (lr=0.0001), train loss 0.00460, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 105/200 (lr=0.0001), train loss 0.00528, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 106/200 (lr=0.0001), train loss 0.00490, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 107/200 (lr=0.0001), train loss 0.00424, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 108/200 (lr=0.0001), train loss 0.00485, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 109/200 (lr=0.0001), train loss 0.00533, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 110 done, starting evaluation\n",
      "Epoch 110/200 (lr=0.0001), train loss 0.00437, valid loss 0.00764, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         1067.15\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           20.20\n",
      "  metrics/test.mAR:           20.00\n",
      "Epoch 111/200 (lr=0.0001), train loss 0.00509, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 112/200 (lr=0.0001), train loss 0.00519, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 113/200 (lr=0.0001), train loss 0.00756, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 114/200 (lr=0.0001), train loss 0.00542, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 115/200 (lr=0.0001), train loss 0.00534, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 116/200 (lr=0.0001), train loss 0.00479, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 117/200 (lr=0.0001), train loss 0.00493, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 118/200 (lr=0.0001), train loss 0.00517, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 119/200 (lr=0.0001), train loss 0.00523, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 120 done, starting evaluation\n",
      "Epoch 120/200 (lr=1e-05), train loss 0.00569, valid loss 0.00765, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         839.66\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           25.15\n",
      "  metrics/test.mAR:           25.00\n",
      "Epoch 121/200 (lr=1e-05), train loss 0.00509, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 122/200 (lr=1e-05), train loss 0.00457, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 123/200 (lr=1e-05), train loss 0.00459, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 124/200 (lr=1e-05), train loss 0.00729, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 125/200 (lr=1e-05), train loss 0.00409, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 126/200 (lr=1e-05), train loss 0.00484, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 127/200 (lr=1e-05), train loss 0.00365, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 128/200 (lr=1e-05), train loss 0.00550, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 129/200 (lr=1e-05), train loss 0.00469, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 130 done, starting evaluation\n",
      "Epoch 130/200 (lr=1e-05), train loss 0.00609, valid loss 0.00739, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         837.34\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           25.15\n",
      "  metrics/test.mAR:           25.00\n",
      "Epoch 131/200 (lr=1e-05), train loss 0.00680, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 132/200 (lr=1e-05), train loss 0.00550, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 133/200 (lr=1e-05), train loss 0.00532, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 134/200 (lr=1e-05), train loss 0.00442, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 135/200 (lr=1e-05), train loss 0.00495, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 136/200 (lr=1e-05), train loss 0.00401, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 137/200 (lr=1e-05), train loss 0.00648, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 138/200 (lr=1e-05), train loss 0.00485, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 139/200 (lr=1e-05), train loss 0.00483, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 140 done, starting evaluation\n",
      "Epoch 140/200 (lr=1e-05), train loss 0.00498, valid loss 0.00713, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         970.15\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           20.20\n",
      "  metrics/test.mAR:           20.00\n",
      "Epoch 141/200 (lr=1e-05), train loss 0.00362, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 142/200 (lr=1e-05), train loss 0.00399, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 143/200 (lr=1e-05), train loss 0.00574, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 144/200 (lr=1e-05), train loss 0.00456, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 145/200 (lr=1e-05), train loss 0.00499, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 146/200 (lr=1e-05), train loss 0.00343, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 147/200 (lr=1e-05), train loss 0.00468, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 148/200 (lr=1e-05), train loss 0.00346, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 149/200 (lr=1e-05), train loss 0.00456, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 150 done, starting evaluation\n",
      "Epoch 150/200 (lr=1e-05), train loss 0.00442, valid loss 0.00716, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         929.65\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           20.20\n",
      "  metrics/test.mAR:           20.00\n",
      "Epoch 151/200 (lr=1e-05), train loss 0.00366, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 152/200 (lr=1e-05), train loss 0.00448, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 153/200 (lr=1e-05), train loss 0.00476, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 154/200 (lr=1e-05), train loss 0.00506, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 155/200 (lr=1e-05), train loss 0.00458, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 156/200 (lr=1e-05), train loss 0.00531, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 157/200 (lr=1e-05), train loss 0.00365, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 158/200 (lr=1e-05), train loss 0.00533, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 159/200 (lr=1e-05), train loss 0.00443, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 160 done, starting evaluation\n",
      "Epoch 160/200 (lr=1e-05), train loss 0.00467, valid loss 0.00718, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         799.13\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           25.15\n",
      "  metrics/test.mAR:           25.00\n",
      "Epoch 161/200 (lr=1e-05), train loss 0.00391, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 162/200 (lr=1e-05), train loss 0.00500, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 163/200 (lr=1e-05), train loss 0.00533, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 164/200 (lr=1e-05), train loss 0.00381, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 165/200 (lr=1e-05), train loss 0.00456, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 166/200 (lr=1e-05), train loss 0.00492, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 167/200 (lr=1e-05), train loss 0.00380, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 168/200 (lr=1e-05), train loss 0.00524, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 169/200 (lr=1e-05), train loss 0.00569, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 170 done, starting evaluation\n",
      "Epoch 170/200 (lr=1e-05), train loss 0.00433, valid loss 0.00706, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         929.57\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           20.20\n",
      "  metrics/test.mAR:           20.00\n",
      "Epoch 171/200 (lr=1e-05), train loss 0.00472, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 172/200 (lr=1e-05), train loss 0.00385, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 173/200 (lr=1e-05), train loss 0.00446, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 174/200 (lr=1e-05), train loss 0.00492, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 175/200 (lr=1e-05), train loss 0.00481, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 176/200 (lr=1e-05), train loss 0.00406, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 177/200 (lr=1e-05), train loss 0.00420, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 178/200 (lr=1e-05), train loss 0.00431, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 179/200 (lr=1e-05), train loss 0.00424, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 180 done, starting evaluation\n",
      "Epoch 180/200 (lr=1e-05), train loss 0.00479, valid loss 0.00694, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         929.48\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           20.20\n",
      "  metrics/test.mAR:           20.00\n",
      "Epoch 181/200 (lr=1e-05), train loss 0.00389, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 182/200 (lr=1e-05), train loss 0.00435, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 183/200 (lr=1e-05), train loss 0.00442, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 184/200 (lr=1e-05), train loss 0.00430, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 185/200 (lr=1e-05), train loss 0.00412, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 186/200 (lr=1e-05), train loss 0.00530, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 187/200 (lr=1e-05), train loss 0.00452, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 188/200 (lr=1e-05), train loss 0.00459, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 189/200 (lr=1e-05), train loss 0.00505, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 190 done, starting evaluation\n",
      "Epoch 190/200 (lr=1e-05), train loss 0.00378, valid loss 0.00692, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         929.18\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           20.20\n",
      "  metrics/test.mAR:           20.00\n",
      "Epoch 191/200 (lr=1e-05), train loss 0.00551, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 192/200 (lr=1e-05), train loss 0.00653, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 193/200 (lr=1e-05), train loss 0.00421, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 194/200 (lr=1e-05), train loss 0.00454, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 195/200 (lr=1e-05), train loss 0.00424, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 196/200 (lr=1e-05), train loss 0.00417, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 197/200 (lr=1e-05), train loss 0.00454, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 198/200 (lr=1e-05), train loss 0.00443, GPU: 3826.0/5804.3 MiB\n",
      "Epoch 199/200 (lr=1e-05), train loss 0.00419, GPU: 3826.0/5804.3 MiB\n",
      "Training for epoch 200 done, starting evaluation\n",
      "Epoch 200/200 (lr=1e-05), train loss 0.00487, valid loss 0.00708, GPU: 3826.0/5804.3 MiB\n",
      "Model performance:\n",
      "  metrics/test.rmse:         1204.28\n",
      "  metrics/test.rmse_pcutoff:    nan\n",
      "  metrics/test.mAP:           20.20\n",
      "  metrics/test.mAR:           20.00\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.train_network(config_path, shuffle=2, displayiters=100, saveiters=1000, maxiters=30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d052f255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation scorer: DLC_Resnet50_cpakFeb17shuffle1_snapshot_best-140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38/38 [00:12<00:00,  3.10it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  5.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results file: DLC_Resnet50_cpakFeb17shuffle1_snapshot_best-140-results.csv\n",
      "Evaluation results for DLC_Resnet50_cpakFeb17shuffle1_snapshot_best-140-results.csv (pcutoff: 0.6):\n",
      "train rmse            1192.80\n",
      "train rmse_pcutoff     851.14\n",
      "train mAP                2.04\n",
      "train mAR                2.89\n",
      "test rmse             1837.26\n",
      "test rmse_pcutoff         NaN\n",
      "test mAP                 0.00\n",
      "test mAR                 0.00\n",
      "Name: (0.95, 1, 140, -1, 0.6), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.evaluate_network(config_path, Shuffles=[1], plotting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c022f00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
